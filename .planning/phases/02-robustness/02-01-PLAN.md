---
phase: 02-robustness
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/types/index.ts
  - src/lib/assemblyai/index.ts
  - src/lib/assemblyai/transcribe.ts
  - src/lib/youtube/extract-audio.ts
  - src/lib/youtube/index.ts
autonomous: true
user_setup:
  - service: AssemblyAI
    why: "Audio transcription with speaker diarization"
    env_vars:
      - name: ASSEMBLYAI_API_KEY
        source: "AssemblyAI Dashboard -> Account -> API Keys (https://www.assemblyai.com/app/account)"
    dashboard_config: []

must_haves:
  truths:
    - "AssemblyAI client can be initialized with API key from environment"
    - "Audio buffer can be extracted from YouTube video ID"
    - "Audio buffer can be transcribed with speaker diarization"
    - "Transcript result includes source information (youtube vs assemblyai)"
  artifacts:
    - path: "src/types/index.ts"
      provides: "TranscriptSource, TranscriptResult, SpeakerUtterance types"
      contains: "TranscriptSource"
    - path: "src/lib/assemblyai/index.ts"
      provides: "AssemblyAI client export"
      exports: ["assemblyai"]
    - path: "src/lib/assemblyai/transcribe.ts"
      provides: "Transcription function with diarization"
      exports: ["transcribeAudio"]
    - path: "src/lib/youtube/extract-audio.ts"
      provides: "Audio extraction function"
      exports: ["extractAudioBuffer"]
  key_links:
    - from: "src/lib/assemblyai/transcribe.ts"
      to: "src/lib/assemblyai/index.ts"
      via: "imports assemblyai client"
      pattern: "import.*assemblyai"
    - from: "src/lib/assemblyai/transcribe.ts"
      to: "src/lib/youtube/extract-audio.ts"
      via: "gets audio buffer for transcription"
      pattern: "extractAudioBuffer"
---

<objective>
Create AssemblyAI transcription backend with audio extraction capability.

Purpose: Enable fallback transcription when YouTube captions are unavailable, with speaker diarization support.
Output: Working AssemblyAI module that can extract audio from YouTube and transcribe with speaker labels.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/02-robustness/02-RESEARCH.md

# Existing codebase patterns
@src/types/index.ts
@src/lib/youtube/index.ts
@src/lib/youtube/fetch-transcript.ts
@src/actions/process-video.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install AssemblyAI SDK and extend types</name>
  <files>
    - package.json
    - src/types/index.ts
  </files>
  <action>
1. Install AssemblyAI SDK:
   ```bash
   npm install assemblyai
   ```

2. Extend `src/types/index.ts` with new types for transcript source tracking and speaker utterances:

```typescript
// Add after existing types:

export type TranscriptSource = 'youtube' | 'assemblyai';

export interface SpeakerUtterance {
  speaker: string;      // "A", "B", "C", etc.
  text: string;
  startMs: number;
  endMs: number;
}

export interface TranscriptResult {
  text: string;                          // Full transcript text (formatted)
  segments: TranscriptSegment[];         // Raw segments for compatibility
  source: TranscriptSource;              // Where transcript came from
  utterances?: SpeakerUtterance[];       // Speaker-labeled utterances (AssemblyAI only)
  hasSpeakers: boolean;                  // True if multiple speakers detected
}
```

3. Update ProcessingStatus type to include new transcription state:
```typescript
export type ProcessingStatus =
  | 'idle'
  | 'fetching-metadata'
  | 'fetching-transcript'
  | 'transcribing-audio'    // NEW: AssemblyAI fallback in progress
  | 'summarizing'
  | 'complete'
  | 'error';
```
  </action>
  <verify>
    - `npm list assemblyai` shows package installed
    - `npx tsc --noEmit` passes (no type errors)
  </verify>
  <done>
    - AssemblyAI SDK installed in dependencies
    - TranscriptSource, SpeakerUtterance, TranscriptResult types defined
    - ProcessingStatus includes 'transcribing-audio' state
  </done>
</task>

<task type="auto">
  <name>Task 2: Create AssemblyAI client and transcription module</name>
  <files>
    - src/lib/assemblyai/index.ts
    - src/lib/assemblyai/transcribe.ts
  </files>
  <action>
1. Create `src/lib/assemblyai/index.ts` - client initialization:
```typescript
import { AssemblyAI } from 'assemblyai';

if (!process.env.ASSEMBLYAI_API_KEY) {
  console.warn('ASSEMBLYAI_API_KEY not set - fallback transcription will fail');
}

export const assemblyai = new AssemblyAI({
  apiKey: process.env.ASSEMBLYAI_API_KEY || '',
});
```

2. Create `src/lib/assemblyai/transcribe.ts` - transcription with diarization:
```typescript
import { assemblyai } from './index';
import { TranscriptResult, TranscriptSegment, SpeakerUtterance } from '@/types';
import { extractAudioBuffer } from '@/lib/youtube/extract-audio';

export async function transcribeAudio(videoId: string): Promise<TranscriptResult> {
  // Step 1: Extract audio from YouTube
  const audioBuffer = await extractAudioBuffer(videoId);

  // Step 2: Transcribe with speaker diarization
  const transcript = await assemblyai.transcripts.transcribe({
    audio: audioBuffer,
    speaker_labels: true,
  });

  if (transcript.status === 'error') {
    throw new Error(transcript.error || 'Transcription failed');
  }

  if (!transcript.text) {
    throw new Error('No transcript text returned');
  }

  // Step 3: Process utterances for speaker labels
  const utterances: SpeakerUtterance[] = (transcript.utterances || []).map(u => ({
    speaker: u.speaker,
    text: u.text,
    startMs: u.start,
    endMs: u.end,
  }));

  // Detect if multiple speakers (only show labels if > 1 unique speaker)
  const uniqueSpeakers = new Set(utterances.map(u => u.speaker));
  const hasSpeakers = uniqueSpeakers.size > 1;

  // Step 4: Build segments from words for compatibility
  const segments: TranscriptSegment[] = (transcript.words || []).map(w => ({
    text: w.text,
    offset: w.start,
    duration: w.end - w.start,
  }));

  // Step 5: Format text with speaker labels if multiple speakers
  const formattedText = hasSpeakers
    ? utterances.map(u => `**Speaker ${u.speaker}:** ${u.text}`).join('\n\n')
    : transcript.text;

  return {
    text: formattedText,
    segments,
    source: 'assemblyai',
    utterances: hasSpeakers ? utterances : undefined,
    hasSpeakers,
  };
}
```

Key implementation notes:
- Only show speaker labels when >1 unique speaker detected (per research pitfall #4)
- Return utterances only when hasSpeakers is true
- Format with markdown bold for speaker names
- Convert AssemblyAI milliseconds to our segment format
  </action>
  <verify>
    - `npx tsc --noEmit` passes
    - Files exist at expected paths: `ls src/lib/assemblyai/`
  </verify>
  <done>
    - AssemblyAI client module exports `assemblyai` instance
    - `transcribeAudio(videoId)` function extracts audio, transcribes, and returns TranscriptResult with speaker labels
  </done>
</task>

<task type="auto">
  <name>Task 3: Create YouTube audio extraction function</name>
  <files>
    - src/lib/youtube/extract-audio.ts
    - src/lib/youtube/index.ts
  </files>
  <action>
1. Create `src/lib/youtube/extract-audio.ts`:
```typescript
import ytdl from '@distube/ytdl-core';

/**
 * Extract audio buffer from YouTube video.
 * Uses @distube/ytdl-core (deprecated but functional).
 *
 * NOTE: This library is deprecated as of Aug 2025.
 * Plan migration to youtubei.js if extraction breaks.
 */
export async function extractAudioBuffer(videoId: string): Promise<Buffer> {
  const url = `https://www.youtube.com/watch?v=${videoId}`;

  try {
    const info = await ytdl.getInfo(url);
    const format = ytdl.chooseFormat(info.formats, { quality: 'highestaudio' });

    if (!format) {
      throw new Error('No audio format available for this video');
    }

    const chunks: Buffer[] = [];
    const stream = ytdl.downloadFromInfo(info, { format });

    return new Promise((resolve, reject) => {
      stream.on('data', (chunk: Buffer) => chunks.push(chunk));
      stream.on('end', () => resolve(Buffer.concat(chunks)));
      stream.on('error', (err: Error) => {
        // Provide clear error messages for common failures
        if (err.message.includes('private') || err.message.includes('unavailable')) {
          reject(new Error('Video is private or unavailable'));
        } else if (err.message.includes('age') || err.message.includes('sign in')) {
          reject(new Error('Video requires age verification'));
        } else if (err.message.includes('region')) {
          reject(new Error('Video is not available in your region'));
        } else {
          reject(new Error(`Failed to extract audio: ${err.message}`));
        }
      });
    });
  } catch (error) {
    if (error instanceof Error) {
      throw error; // Re-throw our formatted errors
    }
    throw new Error('Failed to extract audio from video');
  }
}
```

2. Update `src/lib/youtube/index.ts` to export the new function:
```typescript
export { extractVideoId } from './extract-video-id';
export { fetchVideoMetadata } from './fetch-metadata';
export { fetchTranscript } from './fetch-transcript';
export { formatTranscriptIntoParagraphs } from './format-transcript';
export { extractAudioBuffer } from './extract-audio';  // NEW
```
  </action>
  <verify>
    - `npx tsc --noEmit` passes
    - `grep -r "extractAudioBuffer" src/lib/youtube/` shows export in index.ts
  </verify>
  <done>
    - `extractAudioBuffer(videoId)` extracts audio and returns Buffer
    - Clear error messages for common failure modes (private, age-restricted, region-locked)
    - Function exported from youtube module barrel file
  </done>
</task>

</tasks>

<verification>
1. All new files compile without errors: `npx tsc --noEmit`
2. AssemblyAI SDK installed: `npm list assemblyai`
3. Module structure correct:
   ```bash
   ls src/lib/assemblyai/
   # Should show: index.ts, transcribe.ts
   ```
4. Types include new definitions:
   ```bash
   grep "TranscriptSource" src/types/index.ts
   grep "SpeakerUtterance" src/types/index.ts
   grep "TranscriptResult" src/types/index.ts
   ```
</verification>

<success_criteria>
- AssemblyAI SDK installed and client module created
- Audio extraction function using ytdl-core works
- Types extended for transcript source and speaker tracking
- All code compiles without errors
- Ready for integration into process-video.ts (Plan 02)
</success_criteria>

<output>
After completion, create `.planning/phases/02-robustness/02-01-SUMMARY.md`
</output>
